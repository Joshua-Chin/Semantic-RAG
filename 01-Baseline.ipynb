{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b74260-3bb3-4e2c-a671-44bb0c0c4eff",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0956bb86-2d27-465d-a9a9-76dda1947b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lib.load import extract_data, load_benchmark_corpus\n",
    "\n",
    "\n",
    "extract_data()\n",
    "benchmark, corpus = load_benchmark_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7bd70f-886f-4fbf-beb6-1e7015c75f21",
   "metadata": {},
   "source": [
    "## Split Into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2929d1d0-3cbd-4410-b398-153f3496f312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'start_index': 2}, page_content='At Fiverr we care about your privacy.\\nWe do not sell or rent your personal information to third parties for their direct marketing purposes without your explicit consent.'),\n",
       " Document(metadata={'start_index': 173}, page_content='We do not disclose it to others except as disclosed in this Policy or required to provide you with the services of the Site and mobile applications, meaning - to allow you to buy, sell, share the information you want to share on the Site; to contribute on the forum; pay for products; post reviews and so on; or where we have a legal obligation to do so.'),\n",
       " Document(metadata={'start_index': 530}, page_content='We collect information that you provide us or voluntarily share with other users, and also some general technical information that is automatically gathered by our systems, such as IP address, browser information and cookies to enable you to have a better user experience and a more personalized browsing experience.\\n  We will not share information that you provide us in the process of the registration - including your contact information - except as described in this Policy.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n', '!', '?', '.', ':', ';', ',', ' ', ''],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0,\n",
    "    add_start_index=True,\n",
    ")\n",
    "documents = text_splitter.create_documents(corpus.values())\n",
    "documents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567497ed-7916-4097-9d41-903e5e4ee0f5",
   "metadata": {},
   "source": [
    "## Embed Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b9b6f5-db2f-4868-a294-70ac015f9320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2dfdba759754161a5d96ff197970c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"Qwen/Qwen3-Embedding-8B\",\n",
    "    model_kwargs={\n",
    "        \"quantization_config\": BitsAndBytesConfig(load_in_8bit=True)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3af6a0-036a-429e-819b-bf62b16a1880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d27ed517de9492c96fef0c5cb69995b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d7c218a49242bbbdd6bc514e3ac388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_embeddings = model.encode(\n",
    "    [document.page_content for document in documents],\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "query_embeddings = model.encode(\n",
    "    [test['query'] for test in benchmark],\n",
    "    prompt_name=\"query\",\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "similarities = model.similarity(query_embeddings, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "649c38cf-37c4-477e-9b21-4bc775c334e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.13880909727731075, recall: 0.2661742755955439\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from lib.metrics import precision_recall\n",
    "\n",
    "\n",
    "def evaluate_rag(similarities, topk):\n",
    "    precision = recall = 0\n",
    "    count = 0\n",
    "    indices = torch.argsort(similarities, descending=True)[:, :topk]\n",
    "    for test_idx, document_idxs in enumerate(indices):\n",
    "        # Compute spans\n",
    "        spans_true = []\n",
    "        for snippet in benchmark[test_idx][\"snippets\"]:\n",
    "            spans_true.append(snippet[\"span\"])\n",
    "        spans_pred = []\n",
    "        for idx in document_idxs:\n",
    "            document = documents[idx]\n",
    "            start = document.metadata[\"start_index\"]\n",
    "            length = len(document.page_content)\n",
    "            spans_pred.append((start, start + length))\n",
    "        # Compute precision and recall\n",
    "        p, r = precision_recall(spans_true, spans_pred)\n",
    "        # Update accumulators\n",
    "        precision += p\n",
    "        recall += r\n",
    "        count += 1\n",
    "    return precision / count, recall / count\n",
    "\n",
    "precision, recall = evaluate_rag(similarities, topk=4)\n",
    "print(f\"precision: {precision}, recall: {recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
